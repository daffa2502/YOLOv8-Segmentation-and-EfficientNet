{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# YOLOv8 Segmentation"
      ],
      "metadata": {
        "id": "jubYl9UO1s2X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKS2Co6BpHdr"
      },
      "outputs": [],
      "source": [
        "pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "model = YOLO('yolov8x-seg.yaml')\n",
        "model = YOLO('yolov8x-seg.pt')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cat /content/drive/MyDrive/yolo_fix/yolo_dataset_noaug/data.yaml\n",
        "\n",
        "import yaml\n",
        "with open(\"/content/drive/MyDrive/yolo_fix/yolo_dataset/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])\n",
        "\n",
        "project = \"/content/drive/MyDrive/yolo_fix/results\"\n",
        "name = \"xl250\"\n",
        "\n",
        "results = model.train(data='/content/drive/MyDrive/yolo_fix/yolo_dataset/data.yaml',\n",
        "                      project=project,\n",
        "                      name=name,\n",
        "                      epochs=250)\n",
        "\n",
        "best_model = YOLO('/content/drive/MyDrive/yolo_fix/results/xl250/weights/best.pt')\n",
        "\n",
        "#Evaluate\n",
        "metrics = best_model.val(data='/content/drive/MyDrive/yolo_fix/testing/0/data.yaml',split='test')\n",
        "print(metrics.box.map)\n",
        "\n",
        "#Removing background\n",
        "output_dir = '/content/drive/MyDrive/classifier_dataset'\n",
        "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def process_image(image_path, model, output_dir):\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    resized_image = cv2.resize(image, (800, 800))\n",
        "\n",
        "    results = model(resized_image, conf=0.2, iou=0.3)\n",
        "\n",
        "    masks = np.sum(results[0].masks.data.cpu().numpy(), axis=0)\n",
        "\n",
        "    masks_resized = cv2.resize(masks.astype(np.uint8), (resized_image.shape[1], resized_image.shape[0]))\n",
        "\n",
        "    masks_binary = (masks_resized > 0.5).astype(np.uint8)\n",
        "\n",
        "    processed_image = resized_image.copy()\n",
        "    processed_image[masks_binary == 0] = 255\n",
        "\n",
        "    filename = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    cv2.imwrite(os.path.join(output_dir, f\"{filename}.jpg\"), processed_image)\n",
        "\n",
        "dataset_dir = '/content/drive/MyDrive/Dataset/Hanya Daun/Vertikal'\n",
        "image_files = [f for f in os.listdir(dataset_dir)]\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(dataset_dir, image_file)\n",
        "    process_image(image_path, best_model, output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNet"
      ],
      "metadata": {
        "id": "mOHQRHsv2UFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras_tuner\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB5\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "import keras_tuner as kt\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/classifier_dataset_splitted'\n",
        "train_path = os.path.join(base_dir, 'train')\n",
        "valid_path = os.path.join(base_dir, 'validation')\n",
        "\n",
        "img_height, img_width = 456, 456\n",
        "num_classes = 5\n",
        "\n",
        "# Data Preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "#Hyperparameter tuning\n",
        "def build_model(hp):\n",
        "    base_model = EfficientNetB5(weights='imagenet', include_top=False)\n",
        "    to_freeze = hp.choice('freeze', [42,116,190,294,397,531,574,577])\n",
        "    for layer in base_model.layers[:to_freeze]:\n",
        "      layer.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(hp.Choice('dropout 1', [0.2, 0.5]))(x)\n",
        "    x = Dense(hp.Choice('dense', [512, 1024]), activation='relu')(x)\n",
        "    x = Dropout(hp.Choice('dropout 2', [0.2, 0.5]))(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    predictions = Dense(5, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
        "\n",
        "    if optimizer_choice == 'adam':\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate = hp.Choice('learning_rate', [1e-3, 1e-4, 5e-5, 1e-5]))\n",
        "    else:\n",
        "      optimizer = tf.keras.optimizers.RMSprop(learning_rate = hp.Choice('learning_rate', [1e-3, 1e-4, 5e-5, 1e-5]))\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "tuner = kt.GridSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials = 512,\n",
        "    overwrite=True,\n",
        "    directory='hyperparams_tuning',\n",
        "    project_name='hyperparams_tuning')\n",
        "\n",
        "tuner.search(\n",
        "    train_generator, epochs=20,\n",
        "    validation_data=valid_generator)\n",
        "\n",
        "tuner.results_summary()\n",
        "\n",
        "#Train model with best hps\n",
        "best_hps = tuner.get_best_hyperpamrameters(5)\n",
        "model = build_model(best_hps[0])\n",
        "\n",
        "history = model.fit(train_generator, epochs=50, validation_data=test_generator)\n",
        "\n",
        "#Plot training and validation accuracy\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vmHzMcwnuxdI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}